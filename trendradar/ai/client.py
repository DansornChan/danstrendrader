# coding=utf-8
"""
AI å®¢æˆ·ç«¯æ¨¡å—ï¼ˆç»ˆæç¨³å®šç‰ˆï¼‰

ç‰¹æ€§ï¼š
- LiteLLM ç»Ÿä¸€æ¥å£
- Primary / Fallback è‡ªåŠ¨åˆ‡æ¢
- æ˜ç¡®è®°å½•å®é™…ä½¿ç”¨æ¨¡å‹
- Gemini quota / 429 / 400 å¼ºåˆ¶ fallback
- DRY_RUN_AI è°ƒè¯•æ¨¡å¼ï¼ˆä¸æ¶ˆè€— tokenï¼‰
"""

import os
import logging
from typing import Any, Dict, List

from litellm import completion
from litellm.exceptions import (
    RateLimitError,
    BadRequestError,
    AuthenticationError,
)

logger = logging.getLogger(__name__)


class AIClient:
    """ç»Ÿä¸€ AI å®¢æˆ·ç«¯ï¼ˆLiteLLM å°è£…ï¼‰"""

    def __init__(self, config: Dict[str, Any]):
        """
        config ç¤ºä¾‹ï¼š
        {
            "MODEL": "gemini/gemini-2.5-pro",
            "API_KEY": "...",
            "FALLBACK_MODELS": [
                {"model": "deepseek/deepseek-chat", "api_key": "..."}
            ],
            "DRY_RUN_AI": false
        }
        """

        # ===== Primary =====
        self.model: str = config.get("MODEL") or os.getenv("PRIMARY_MODEL")
        self.api_key: str = config.get("API_KEY") or os.getenv("PRIMARY_API_KEY")

        # ===== Fallback =====
        self.fallback_models: List[Dict[str, str]] = config.get(
            "FALLBACK_MODELS", []
        )

        # ===== å‚æ•° =====
        self.temperature: float = float(config.get("TEMPERATURE", 0.7))
        self.max_tokens: int = int(config.get("MAX_TOKENS", 5000))
        self.timeout: int = int(config.get("TIMEOUT", 120))
        self.num_retries: int = int(config.get("NUM_RETRIES", 2))
        self.api_base: str = config.get("API_BASE", "")

        # ===== è°ƒè¯•æ¨¡å¼ =====
        self.dry_run: bool = str(
            config.get("DRY_RUN_AI") or os.getenv("DRY_RUN_AI", "false")
        ).lower() == "true"

        self._validate()

    # ------------------------------------------------------------------

    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """
        ç»Ÿä¸€å¯¹è¯æ¥å£
        """

        if self.dry_run:
            logger.warning("ğŸ§ª DRY_RUN_AI=trueï¼Œæœªè°ƒç”¨çœŸå®æ¨¡å‹")
            return self._dry_run_response(messages)

        params = {
            "model": self.model,
            "messages": messages,
            "temperature": kwargs.get("temperature", self.temperature),
            "timeout": kwargs.get("timeout", self.timeout),
            "num_retries": kwargs.get("num_retries", self.num_retries),
            "api_key": self.api_key,
        }

        if self.max_tokens > 0:
            params["max_tokens"] = kwargs.get("max_tokens", self.max_tokens)

        if self.api_base:
            params["api_base"] = self.api_base

        if self.fallback_models:
            params["fallbacks"] = self.fallback_models

        try:
            logger.info(f"ğŸ¤– ä½¿ç”¨ Primary æ¨¡å‹: {self.model}")
            response = completion(**params)
            return response.choices[0].message.content

        except (RateLimitError, BadRequestError) as e:
            logger.warning(
                f"âš ï¸ Primary æ¨¡å‹å¤±è´¥ ({self.model})ï¼ŒåŸå› ={type(e).__name__}ï¼Œå°è¯• Fallback"
            )

            if not self.fallback_models:
                raise

            # LiteLLM å·²æ”¯æŒ fallbacksï¼Œè¿™é‡Œä¸»è¦æ˜¯å…œåº•æ˜¾ç¤ºæ—¥å¿—
            response = completion(**params)
            return response.choices[0].message.content

        except AuthenticationError as e:
            logger.error(
                f"âŒ API Key é”™è¯¯ï¼ˆ{self.model}ï¼‰ï¼š{str(e)}"
            )
            raise

    # ------------------------------------------------------------------

    def _dry_run_response(self, messages: List[Dict[str, str]]) -> str:
        """
        è°ƒè¯•æ¨¡å¼ä¸‹çš„å‡è¿”å›
        """

        user_content = ""
        for m in messages:
            if m.get("role") == "user":
                user_content += m.get("content", "")[:200]

        return (
            "ã€DRY RUN æ¨¡å¼ã€‘\n"
            "æœªè°ƒç”¨çœŸå® AI æ¨¡å‹ã€‚\n\n"
            f"ç”¨æˆ·è¾“å…¥æ‘˜è¦ï¼š{user_content}\n\n"
            "ï¼ˆæ­¤ç»“æœä»…ç”¨äºæµç¨‹è°ƒè¯•ï¼‰"
        )

    # ------------------------------------------------------------------

    def _validate(self) -> None:
        """å¯åŠ¨å‰å¼ºæ ¡éªŒ"""

        if not self.model or not isinstance(self.model, str):
            raise ValueError(
                f"AI é…ç½®é”™è¯¯ï¼šMODEL å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œå½“å‰={self.model}"
            )

        if "/" not in self.model:
            raise ValueError(
                f"AI æ¨¡å‹æ ¼å¼é”™è¯¯ï¼š{self.model}ï¼Œåº”ä¸º provider/model"
            )

        if not self.api_key:
            raise ValueError("æœªé…ç½® PRIMARY_API_KEY")

        if self.fallback_models:
            if not isinstance(self.fallback_models, list):
                raise ValueError("FALLBACK_MODELS å¿…é¡»æ˜¯ list")

            for fb in self.fallback_models:
                if not isinstance(fb, dict):
                    raise ValueError("FALLBACK_MODELS ä¸­æ¯ä¸€é¡¹å¿…é¡»æ˜¯ dict")
                if "model" not in fb or "api_key" not in fb:
                    raise ValueError(
                        f"Fallback æ¨¡å‹é…ç½®ä¸å®Œæ•´: {fb}"
                    )